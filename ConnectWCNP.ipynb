{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOu+GYDolrpVdL1U5X59n7n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tyukei/WCNSProject/blob/main/ConnectWCNP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# WCN\n",
        "## Reference\n",
        "- whisper\n",
        "https://note.com/k_masaki/n/na6a523648616\n",
        "\n",
        "- ChatGPT\n",
        "https://note.com/nero1014/n/n09a2ce7843b8\n",
        "\n",
        "- Notion\n",
        "https://yshr10ic.com/2022/01/10/notion-google-colab/\n",
        "\n",
        "\n",
        "## TODO\n",
        "\n",
        "```python\n",
        "def GetOpenaiApi():\n",
        "  return '<CPTAPI>'\n",
        "\n",
        "def GetNotionToken():\n",
        "  return '<NOTIONTOKEN>'   \n",
        "\n",
        "def GetNotionDB():\n",
        "  return '<NOTIONDBID>'\n",
        "\n",
        "```\n",
        "\n",
        "1. make ```key.py``` and copy paste this code at drive/MyDrive/ColabNotebooks\n",
        "\n",
        "1. Get ChatGPT API\n",
        "https://platform.openai.com/account/api-keys\n",
        "\n",
        "1. Copy Paste Chat GPT API ```'<CPTAPI>'```\n",
        "\n",
        "1. Add Integration https://www.notion.so/my-integrations\n",
        "\n",
        "1. Copy Paste Notion Token ```'<NOTIONTOKEN>'```\n",
        "\n",
        "1. Make DataBase in Notion and get id\n",
        "  \n",
        "  ex) `https://www.notion.so/<Username>/<DataBaseID>?v=<ViewID>`\n",
        "\n",
        "1. Copy Paste Notion DataBase ID ```'<NOTIONDBID>'```\n",
        "\n",
        "1. Set Other parameters\n",
        "\n",
        "* WHISPER_MODEL = [base, small, large] \\\\\n",
        "base is quick but not correct so much \\\\\n",
        "large is good score but takes long time\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "h4q1CYTz7hPd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Environment"
      ],
      "metadata": {
        "id": "U7ewn_V9w_gU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parameters"
      ],
      "metadata": {
        "id": "gyW4Kzw45wCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "WHISPER_MODEL =\"large\"\n",
        "ZOOM_FILE_PATH = \"/content/drive/MyDrive/Zoom\"\n",
        "VOICE_LANGUAGE =\"ja\"\n",
        "GPT_ROLL=\"あなたは書記です。音声データは次のものです。\" \n",
        "GPT_PROMPT_SUMMARY=\"要約を書いてください。\"\n",
        "GPT_PROMPT_TITLE=\"内容を一言で表してください\""
      ],
      "metadata": {
        "id": "EBRjAwNtzJ2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Whisper"
      ],
      "metadata": {
        "id": "4GCyf3rIrGfd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EL2VnCYYq69j",
        "outputId": "5ab67e93-e2f1-440b-8c35-33b83c3be796"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-eqp6ow9r\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-eqp6ow9r\n",
            "  Resolved https://github.com/openai/whisper.git to commit c09a7ae299c4c34c5839a76380ae407e7d785914\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (9.1.0)\n",
            "Collecting tiktoken==0.3.1\n",
            "  Downloading tiktoken-0.3.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (2.0.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (2.0.0+cu118)\n",
            "Collecting ffmpeg-python==0.2.0\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (1.22.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (4.65.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (0.56.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from ffmpeg-python==0.2.0->openai-whisper==20230314) (0.18.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.9/dist-packages (from tiktoken==0.3.1->openai-whisper==20230314) (2022.10.31)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.9/dist-packages (from tiktoken==0.3.1->openai-whisper==20230314) (2.27.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->openai-whisper==20230314) (16.0.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->openai-whisper==20230314) (3.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->openai-whisper==20230314) (3.11.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba->openai-whisper==20230314) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from numba->openai-whisper==20230314) (67.6.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch->openai-whisper==20230314) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch->openai-whisper==20230314) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->openai-whisper==20230314) (4.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch->openai-whisper==20230314) (3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (2.0.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch->openai-whisper==20230314) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch->openai-whisper==20230314) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20230314-py3-none-any.whl size=798038 sha256=67066311e33f688d2a0ee9fe6d690e4f5db7180898c90733737f66a499c44fcc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1zie8n3t/wheels/fe/03/29/e7919208d11b4ab32972cb448bb84a9a675d92cd52c9a48341\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: ffmpeg-python, tiktoken, openai-whisper\n",
            "Successfully installed ffmpeg-python-0.2.0 openai-whisper-20230314 tiktoken-0.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper"
      ],
      "metadata": {
        "id": "Hwr2hgNWrmoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Chatgpt"
      ],
      "metadata": {
        "id": "e-EKoS_zrTvw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkDrgaeVrJ80",
        "outputId": "5d91793c-ef1e-4cb4-d40b-c83258d8167e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.4-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.3/70.3 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.4 yarl-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai"
      ],
      "metadata": {
        "id": "upu7_zZBrXGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import necessary libraries"
      ],
      "metadata": {
        "id": "EusbJsiVvxYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "import datetime\n",
        "import json\n",
        "from pprint import pprint\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "import textwrap"
      ],
      "metadata": {
        "id": "4TJRy4eSsgck"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "import sys\n",
        "drive.mount('/content/drive')\n",
        "sys.path.append('/content/drive/MyDrive/Key/')\n",
        "import makekey\n",
        "openai.api_key  = makekey.GetOpenaiApi()\n",
        "NOTION_TOKEN = makekey.GetNotionToken()\n",
        "NOTION_DB = makekey.GetNotionDB()\n",
        "SLACK_WEBHOOK = makekey.GetSlackAPI()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15DANFr4cVnI",
        "outputId": "9fa2765d-0630-4206-88b3-3825b0e51151"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Whisper model"
      ],
      "metadata": {
        "id": "hUd4P2BGxMcv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisper.load_model(WHISPER_MODEL)"
      ],
      "metadata": {
        "id": "xvsv67V6rvZ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c25579b5-9d9f-486e-bc14-e696cc7e9c56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 2.87G/2.87G [00:47<00:00, 65.7MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Notion setting"
      ],
      "metadata": {
        "id": "TMRoOWNExVDU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Config:\n",
        "    notion_token = NOTION_TOKEN\n",
        "    notion_endpoint = 'https://api.notion.com/v1'\n",
        "    database_id = NOTION_DB\n",
        "    headers = {\n",
        "        'Authorization': f'Bearer {notion_token}',\n",
        "        'Content-Type': 'application/json',\n",
        "        'Notion-Version': '2021-08-16'\n",
        "    }\n",
        "\n",
        "class PropertyType:\n",
        "    TITLE = 'title'\n",
        "    RICH_TEXT = 'rich_text'\n",
        "    NUMBER = 'number'\n",
        "    DATE = 'date'\n",
        "    CHECKBOX = 'checkbox'\n",
        "    SELECT = 'select'\n",
        "    MULTI_SELECT = 'multi_select'\n",
        "    RELATION = 'relation'\n",
        "\n",
        "class Cell:\n",
        "    def __init__(self, key, properties, values):\n",
        "        self.key = key\n",
        "        self.property_type = properties[self.key]\n",
        "        self.values = values\n",
        "\n",
        "    def to_dict(self):\n",
        "        if self.property_type in [PropertyType.TITLE, PropertyType.RICH_TEXT]:\n",
        "            return self._to_dict_text()\n",
        "        elif self.property_type == PropertyType.DATE:\n",
        "            return self._to_dict_pattern2('start')\n",
        "        elif self.property_type == PropertyType.NUMBER:\n",
        "            return self._to_dict_pattern1(round(self.values, 5))\n",
        "        elif self.property_type == PropertyType.CHECKBOX:\n",
        "            return self._to_dict_pattern1(self.values)\n",
        "        elif self.property_type == PropertyType.SELECT:\n",
        "            return self._to_dict_pattern2('name')\n",
        "        elif self.property_type == PropertyType.MULTI_SELECT:\n",
        "            values = self.get_multi_select_values()\n",
        "            return self._to_dict_pattern1(values)\n",
        "        elif self.property_type == PropertyType.RELATION:\n",
        "            return self._to_dict_relation()\n",
        "\n",
        "    def _to_dict_text(self):\n",
        "        return {\n",
        "            self.key: {\n",
        "                self.property_type: [\n",
        "                    {\n",
        "                        'text': {\n",
        "                            'content': self.values\n",
        "                        }\n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def _to_dict_relation(self):\n",
        "        return {\n",
        "            self.key: {\n",
        "                self.property_type: [\n",
        "                    {\n",
        "                        'id': self.get_page_id()\n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def _to_dict_pattern1(self, values):\n",
        "        return {\n",
        "            self.key: {\n",
        "                self.property_type: values\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def _to_dict_pattern2(self, name):\n",
        "        return {\n",
        "            self.key: {\n",
        "                self.property_type: {\n",
        "                    name: self.values\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def get_multi_select_values(self):\n",
        "        values = []\n",
        "        if isinstance(self.values, str):\n",
        "            values.append({'name': self.values})\n",
        "        else:\n",
        "            for val in self.values:\n",
        "                values.append({'name': val})\n",
        "        return values\n",
        "    \n",
        "    def get_page_id(self):\n",
        "        body = {\n",
        "            'filter': {\n",
        "                'property': 'Exp',\n",
        "                'text': {\n",
        "                    'contains': self.values\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "        url = f'{Config.notion_endpoint}/databases/{Config.database_id}/query'\n",
        "        response = requests.request('POST', url=url, headers=Config.headers, data=json.dumps(body))\n",
        "\n",
        "        return response.json()['results'][0]['id']\n",
        "\n",
        "def to_notion(cells):\n",
        "    props = {}\n",
        "    \n",
        "    for cell in cells:\n",
        "        props.update(cell.to_dict())\n",
        "    \n",
        "    body = {\n",
        "        'parent': {\n",
        "            'database_id': Config.database_id\n",
        "        },\n",
        "        'properties': props,\n",
        "    }\n",
        "\n",
        "    url = f'{Config.notion_endpoint}/pages'\n",
        "    return requests.request('POST', url=url, headers=Config.headers, data=json.dumps(body))"
      ],
      "metadata": {
        "id": "FRqDaoGIwi_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Whisper, Chatgpt and Notion"
      ],
      "metadata": {
        "id": "xilhznIYycc8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def RunWhisper():\n",
        "  m4a_files = glob.glob(ZOOM_FILE_PATH + \"/*/*.m4a\")\n",
        "  if m4a_files[0] is None:\n",
        "    return 'null'\n",
        "  elif not os.path.isfile(m4a_files[0]):  \n",
        "    print('not find file')\n",
        "    return 'null'\n",
        "  else:\n",
        "    print(\"Get \" + m4a_files[0])\n",
        "    print('Creating Text by Whisper')\n",
        "    result = model.transcribe(m4a_files[0], language=VOICE_LANGUAGE)\n",
        "    print(result[\"text\"])\n",
        "    return result[\"text\"]\n"
      ],
      "metadata": {
        "id": "WQmLJcrx2bb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def GetGPT(role,content):\n",
        "  result = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo-0301\",\n",
        "    messages=[\n",
        "      {\"role\": role, \"content\": content},\n",
        "    ]\n",
        "  )\n",
        "  text_result= result['choices'][0]['message']['content']"
      ],
      "metadata": {
        "id": "G6OJtcNYOC-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def RunGPT(whisper_result):\n",
        "  print('Creating Summary and Title by ChatGPT')\n",
        "  result_summary = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo-0301\",\n",
        "    messages=[\n",
        "      {\"role\": \"system\", \"content\": GPT_ROLL+ whisper_result},\n",
        "      {\"role\": \"user\", \"content\":GPT_PROMPT_SUMMARY}\n",
        "    ]\n",
        "  )\n",
        "  text_summary = result_summary['choices'][0]['message']['content']\n",
        "  print(\"Summary:\"+ text_summary)\n",
        "  result_title = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo-0301\",\n",
        "    messages=[\n",
        "      {\"role\": \"assistant\", \"content\": result_summary['choices'][0]['message']['content']},\n",
        "      {\"role\": \"user\", \"content\":GPT_PROMPT_TITLE + whisper_result}\n",
        "    ]\n",
        "  )\n",
        "  text_title = result_title['choices'][0]['message']['content']\n",
        "  print(\"Title:\" + text_title)\n",
        "  return [text_summary,text_title]"
      ],
      "metadata": {
        "id": "oKLmq5v42wz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def RunSendNotion(whisper_result,gpt_result):\n",
        "  print('Creating Notion Page')\n",
        "  response = requests.request('GET', url=f'{Config.notion_endpoint}/databases/{Config.database_id}', headers=Config.headers) \n",
        "  properties = {}\n",
        "  for k, v in response.json()['properties'].items():\n",
        "      properties[k] = v['type']\n",
        "  jst = datetime.datetime.now() + datetime.timedelta(hours=9)\n",
        "  cells = [\n",
        "      Cell('Name', properties, gpt_result[1]),\n",
        "      Cell('Date', properties, jst.strftime('%Y%m%d-%H:%M')),\n",
        "      Cell('Summary', properties, gpt_result[0]),\n",
        "      Cell('AllContext', properties, whisper_result)\n",
        "  ]\n",
        "  result = to_notion(cells)\n",
        "  # pprint(result)\n",
        "  return result"
      ],
      "metadata": {
        "id": "BCqD0VOE25BM"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def SendSlack(message):\n",
        "# 任意のメッセージを通知する関数\n",
        "    # 作成したWebhook URL\n",
        "    url =  SLACK_WEBHOOK\n",
        "    data = json.dumps({'text': message})\n",
        "    headers = {'content-type': 'application/json'}\n",
        "    requests.post(url, data=data, headers=headers)\n",
        "\n",
        "def RunSendSlack(notion_result):\n",
        "    SendSlack(notion_result.json()['properties']['Date']['multi_select'][0]['name'])\n",
        "    SendSlack(notion_result.json()['properties']['Name']['title'][0]['plain_text'])\n",
        "    SendSlack(notion_result.json()['properties']['Summary']['rich_text'][0]['plain_text'])\n",
        "    print('RSended to slack')"
      ],
      "metadata": {
        "id": "Eib3044OpQXD"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "whisper_result = RunWhisper()\n",
        "if whisper_result == 'null':\n",
        "  exit()\n",
        "  \n",
        "gpt_result = RunGPT(whisper_result)\n",
        "notion_result = RunSendNotion(whisper_result,gpt_result)\n",
        "if notion_result.status_code == requests.codes.ok:\n",
        "  RunSendSlack(notion_result)"
      ],
      "metadata": {
        "id": "oeJfkSO7ry_W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7533a5da-1a03-450c-ea2d-a455db06a8de"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get /content/drive/MyDrive/Zoom/2023-04-16 21.53.36 Keita Nakata's Zoom Meeting/audio00.m4a\n",
            "Creating Text by Whisper\n",
            "今日は朝おにぎりを食べて、昼にスパゲティを食べました。夜はカレーを食べる予定です。\n",
            "Creating Summary and Title by ChatGPT\n",
            "Summary:人物は朝におにぎりを食べ、昼にスパゲティを食べ、夜はカレーを食べる予定である。\n",
            "Title:一日三食を計画している。\n",
            "Creating Notion Page\n",
            "RSended to slack\n"
          ]
        }
      ]
    }
  ]
}